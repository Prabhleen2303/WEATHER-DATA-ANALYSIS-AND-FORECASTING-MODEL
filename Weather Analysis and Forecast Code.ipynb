{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85085170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and configuration\n",
    "import os, sqlite3, warnings\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Paths (change if needed)\n",
    "CSV_PATH = r\"C:\\Users\\hp\\OneDrive\\Desktop\\Weather Prediction Model\\weather_data.csv\"   # <- change this if your CSV is elsewhere\n",
    "OUTDIR = \"/mnt/data\"\n",
    "DB_PATH = os.path.join(OUTDIR, \"weather_weather.db\")\n",
    "PRED_CSV_PATH = os.path.join(OUTDIR, \"weather_predictions.csv\")\n",
    "\n",
    "print('CSV_PATH =', CSV_PATH)\n",
    "print('Outputs will be saved to:', OUTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2b46e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV and basic checks\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    raise FileNotFoundError(f'CSV not found at {CSV_PATH}. Upload your CSV or change CSV_PATH.')\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print('Loaded CSV with shape:', df.shape)\n",
    "display(df.head())\n",
    "\n",
    "# helper to detect columns\n",
    "def find_date_column(df):\n",
    "    for col in df.columns:\n",
    "        if col.lower() in ('date','datetime','day','timestamp'):\n",
    "            return col\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            pd.to_datetime(df[col])\n",
    "            return col\n",
    "        except Exception:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "def find_temp_and_rain_columns(df):\n",
    "    temp_col = None; rain_col = None\n",
    "    for col in df.columns:\n",
    "        lname = col.lower()\n",
    "        if temp_col is None and ('temp' in lname or 'temperature' in lname):\n",
    "            temp_col = col\n",
    "        if rain_col is None and ('rain' in lname or 'precip' in lname):\n",
    "            rain_col = col\n",
    "    return temp_col, rain_col\n",
    "\n",
    "date_col = find_date_column(df)\n",
    "if date_col is not None:\n",
    "    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "    df = df.sort_values(by=date_col).reset_index(drop=True)\n",
    "else:\n",
    "    df = df.reset_index().rename(columns={'index':'synthetic_index'})\n",
    "    date_col = 'synthetic_index'\n",
    "    df[date_col] = pd.to_datetime(df[date_col], unit='D', origin='1970-01-01')\n",
    "\n",
    "temp_col, rain_col = find_temp_and_rain_columns(df)\n",
    "if temp_col is None or rain_col is None:\n",
    "    raise ValueError('Could not detect temp or rain columns. Ensure names include \"temp\" and \"rain\"/\"precip\".\\nFound columns: ' + ', '.join(df.columns))\n",
    "\n",
    "df[temp_col] = pd.to_numeric(df[temp_col], errors='coerce')\n",
    "df[rain_col] = pd.to_numeric(df[rain_col], errors='coerce')\n",
    "df = df.dropna(subset=[temp_col, rain_col], how='all').reset_index(drop=True)\n",
    "\n",
    "print('Using date_col =', date_col, ', temp_col =', temp_col, ', rain_col =', rain_col)\n",
    "print('\\nLast 5 rows:')\n",
    "display(df.tail())\n",
    "\n",
    "# Save raw table to SQLite DB (replace)\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "df_for_db = df.copy()\n",
    "if 'predicted' not in df_for_db.columns:\n",
    "    df_for_db['predicted'] = 0\n",
    "df_for_db.to_sql('weather', conn, if_exists='replace', index=False)\n",
    "conn.commit(); conn.close()\n",
    "print('Saved raw data to DB at', DB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3459a82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern analysis (last 7 days) and feature engineering\n",
    "last7 = df.tail(7).copy()\n",
    "print('Pattern analysis (last 7 days):')\n",
    "temps = last7[temp_col].values\n",
    "rains = last7[rain_col].values\n",
    "print(' - temp_mean:', float(np.nanmean(temps)))\n",
    "print(' - temp_median:', float(np.nanmedian(temps)))\n",
    "print(' - temp_std:', float(np.nanstd(temps)))\n",
    "print(' - temp_trend:', 'increasing' if temps[-1] > temps[0] else ('decreasing' if temps[-1] < temps[0] else 'flat'))\n",
    "print(' - rain_total:', float(np.nansum(rains)))\n",
    "print(' - rain_days:', int(np.sum(~np.isnan(rains) & (rains>0))))\n",
    "\n",
    "# plots for last 7 days\n",
    "plt.figure(figsize=(8,3)); plt.plot(last7[date_col], last7[temp_col], marker='o'); plt.title('Temperature - last 7 days'); plt.xlabel('Date'); plt.ylabel('Temperature'); plt.tight_layout(); plt.show()\n",
    "plt.figure(figsize=(8,3)); plt.plot(last7[date_col], last7[rain_col], marker='o'); plt.title('Rainfall - last 7 days'); plt.xlabel('Date'); plt.ylabel('Rainfall'); plt.tight_layout(); plt.show()\n",
    "\n",
    "# Feature engineering: lags and rolling features\n",
    "nlags = 3\n",
    "df_feat = df[[date_col, temp_col, rain_col]].copy().set_index(date_col)\n",
    "for lag in range(1, nlags+1):\n",
    "    df_feat[f'temp_lag_{lag}'] = df_feat[temp_col].shift(lag)\n",
    "    df_feat[f'rain_lag_{lag}'] = df_feat[rain_col].shift(lag)\n",
    "df_feat['temp_roll_3'] = df_feat[temp_col].rolling(window=3, min_periods=1).mean().shift(1)\n",
    "df_feat['rain_roll_3'] = df_feat[rain_col].rolling(window=3, min_periods=1).mean().shift(1)\n",
    "\n",
    "df_clean = df_feat.dropna().copy()\n",
    "print('\\nAfter feature creation, rows available for modelling:', len(df_clean))\n",
    "display(df_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc6c14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling and evaluation (Temperature and Rainfall separately)\n",
    "feature_cols = [c for c in df_clean.columns if c not in (temp_col, rain_col)]\n",
    "X = df_clean[feature_cols].values\n",
    "y_temp = df_clean[temp_col].values\n",
    "y_rain = df_clean[rain_col].values\n",
    "\n",
    "def evaluate_models(X, y, n_splits=3):\n",
    "    tscv = TimeSeriesSplit(n_splits=max(1, min(n_splits, len(X)-1)))\n",
    "    models = {\n",
    "        'LinearRegression': Pipeline([('lr', LinearRegression())]),\n",
    "        'DecisionTree': Pipeline([('dt', DecisionTreeRegressor(random_state=42))]),\n",
    "        'SVR': Pipeline([('scaler', StandardScaler()), ('svr', SVR())])\n",
    "    }\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        maes, rmses, r2s = [], [], []\n",
    "        splits = list(tscv.split(X)) if len(X) > 1 else []\n",
    "        if len(splits) == 0:\n",
    "            if len(X) < 2:\n",
    "                maes.append(np.nan); rmses.append(np.nan); r2s.append(np.nan)\n",
    "            else:\n",
    "                train_idx = np.arange(max(1, len(X)-1)); test_idx = np.array([len(X)-1]); splits = [(train_idx, test_idx)]\n",
    "        for train_idx, test_idx in splits:\n",
    "            Xtr, Xte = X[train_idx], X[test_idx]\n",
    "            ytr, yte = y[train_idx], y[test_idx]\n",
    "            try:\n",
    "                model.fit(Xtr, ytr)\n",
    "                ypred = model.predict(Xte)\n",
    "                maes.append(mean_absolute_error(yte, ypred))\n",
    "                rmses.append(mean_squared_error(yte, ypred, squared=False))\n",
    "                r2s.append(r2_score(yte, ypred) if len(yte)>1 else np.nan)\n",
    "            except Exception as e:\n",
    "                maes.append(np.nan); rmses.append(np.nan); r2s.append(np.nan)\n",
    "        results[name] = {'mae_mean': float(np.nanmean(maes)), 'rmse_mean': float(np.nanmean(rmses)), 'r2_mean': float(np.nanmean(r2s)), 'model': model}\n",
    "    return results\n",
    "\n",
    "print('Training & evaluating models for Temperature...')\n",
    "temp_results = evaluate_models(X, y_temp, n_splits=3)\n",
    "for name, res in temp_results.items():\n",
    "    print(f\" - {name}: MAE={res['mae_mean']:.4f}, RMSE={res['rmse_mean']:.4f}, R2={res['r2_mean']:.4f}\")\n",
    "\n",
    "print('\\nTraining & evaluating models for Rainfall...')\n",
    "rain_results = evaluate_models(X, y_rain, n_splits=3)\n",
    "for name, res in rain_results.items():\n",
    "    print(f\" - {name}: MAE={res['mae_mean']:.4f}, RMSE={res['rmse_mean']:.4f}, R2={res['r2_mean']:.4f}\")\n",
    "\n",
    "# Choose best by RMSE\n",
    "best_temp_name = min(temp_results.keys(), key=lambda k: temp_results[k]['rmse_mean'] if not np.isnan(temp_results[k]['rmse_mean']) else 1e9)\n",
    "best_rain_name = min(rain_results.keys(), key=lambda k: rain_results[k]['rmse_mean'] if not np.isnan(rain_results[k]['rmse_mean']) else 1e9)\n",
    "best_temp_model = temp_results[best_temp_name]['model']\n",
    "best_rain_model = rain_results[best_rain_name]['model']\n",
    "\n",
    "# Fit on entire cleaned data\n",
    "best_temp_model.fit(X, y_temp)\n",
    "best_rain_model.fit(X, y_rain)\n",
    "print('\\nSelected models -> Temperature:', best_temp_name, ', Rainfall:', best_rain_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e733a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next-day (8th day) prediction and save outputs\n",
    "# Prepare next-day features from most recent values\n",
    "last_index = df_feat.index.max()\n",
    "next_features = {}\n",
    "for lag in range(1, nlags+1):\n",
    "    next_features[f'temp_lag_{lag}'] = df_feat[temp_col].iloc[-lag] if len(df_feat) >= lag else np.nan\n",
    "    next_features[f'rain_lag_{lag}'] = df_feat[rain_col].iloc[-lag] if len(df_feat) >= lag else np.nan\n",
    "next_features['temp_roll_3'] = df_feat[temp_col].tail(3).mean() if len(df_feat) >= 1 else np.nan\n",
    "next_features['rain_roll_3'] = df_feat[rain_col].tail(3).mean() if len(df_feat) >= 1 else np.nan\n",
    "\n",
    "X_next = np.array([next_features[c] for c in feature_cols]).reshape(1, -1)\n",
    "temp_pred = best_temp_model.predict(X_next)[0]\n",
    "rain_pred = best_rain_model.predict(X_next)[0]\n",
    "\n",
    "# compute predicted date (assume daily)\n",
    "try:\n",
    "    if isinstance(last_index, pd.Timestamp):\n",
    "        if len(df_feat.index) >= 2:\n",
    "            delta = df_feat.index[-1] - df_feat.index[-2]\n",
    "            next_date = df_feat.index[-1] + delta\n",
    "        else:\n",
    "            next_date = df_feat.index[-1] + timedelta(days=1)\n",
    "    else:\n",
    "        next_date = pd.to_datetime(df_feat.index.max()) + timedelta(days=1)\n",
    "except Exception:\n",
    "    next_date = pd.to_datetime(df_feat.index.max()) + timedelta(days=1)\n",
    "\n",
    "pred_row = {date_col: next_date, temp_col: float(temp_pred), rain_col: float(rain_pred)}\n",
    "pred_row['predicted'] = 1\n",
    "pred_row['model_temp'] = best_temp_name\n",
    "pred_row['model_rain'] = best_rain_name\n",
    "pred_row.update(next_features)\n",
    "\n",
    "pred_df = pd.DataFrame([pred_row])\n",
    "print('\\nNext-day prediction (8th day):')\n",
    "display(pred_df.rename(columns={date_col: 'date', temp_col: 'temperature', rain_col: 'rainfall'}))\n",
    "\n",
    "# Append prediction to DB\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "df_for_db = pd.read_sql_query('SELECT * FROM weather LIMIT 1;', conn)  # just to get schema\n",
    "pred_to_write = pred_df.copy()\n",
    "# ensure all columns exist\n",
    "for col in df_for_db.columns:\n",
    "    if col not in pred_to_write.columns:\n",
    "        pred_to_write[col] = np.nan\n",
    "pred_to_write = pred_to_write[df_for_db.columns]\n",
    "pred_to_write.to_sql('weather', conn, if_exists='append', index=False)\n",
    "conn.commit(); conn.close()\n",
    "print('Appended prediction to DB at', DB_PATH)\n",
    "\n",
    "# Save prediction CSV\n",
    "out_pred = pred_df.rename(columns={date_col: 'date', temp_col: 'temperature', rain_col: 'rainfall'})\n",
    "out_pred.to_csv(PRED_CSV_PATH, index=False)\n",
    "print('Saved prediction CSV to', PRED_CSV_PATH)\n",
    "\n",
    "# Plots: actual vs predicted for last part\n",
    "try:\n",
    "    y_temp_all = best_temp_model.predict(X)\n",
    "    y_rain_all = best_rain_model.predict(X)\n",
    "    nplot = min(30, len(df_clean))\n",
    "    idx = df_clean.index[-nplot:]\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.plot(idx, df_clean[temp_col].iloc[-nplot:], label='actual')\n",
    "    plt.plot(idx, y_temp_all[-nplot:], linestyle='--', label='predicted')\n",
    "    plt.title('Temperature: Actual vs Predicted (last points)'); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.plot(idx, df_clean[rain_col].iloc[-nplot:], label='actual')\n",
    "    plt.plot(idx, y_rain_all[-nplot:], linestyle='--', label='predicted')\n",
    "    plt.title('Rainfall: Actual vs Predicted (last points)'); plt.legend(); plt.tight_layout(); plt.show()\n",
    "except Exception as e:\n",
    "    print('Plotting failed:', e)\n",
    "\n",
    "print('\\nNotebook run complete. Outputs:') \n",
    "print(' - Prediction CSV:', PRED_CSV_PATH)\n",
    "print(' - SQLite DB:', DB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3261f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import additional libraries for EDA\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"=== EXPLORATORY DATA ANALYSIS ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96105f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Basic data overview and statistics\n",
    "print(\"Dataset Overview:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(\"\\nBasic Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "display(df.describe())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab1c673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Rainfall distribution analysis\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Pie chart for rainfall distribution\n",
    "plt.subplot(1, 3, 1)\n",
    "if rain_col in df.columns:\n",
    "    rainfall_counts = df[rain_col].value_counts()\n",
    "    # Convert to binary (rain/no rain) if continuous\n",
    "    if rainfall_counts.shape[0] > 10:  # If continuous, create binary\n",
    "        df_rain_binary = (df[rain_col] > 0).astype(int)\n",
    "        rainfall_binary_counts = df_rain_binary.value_counts()\n",
    "        plt.pie(rainfall_binary_counts.values, \n",
    "                labels=['No Rain', 'Rain'], \n",
    "                autopct='%1.1f%%', \n",
    "                colors=['skyblue', 'lightcoral'])\n",
    "        plt.title('Rainfall Distribution (Binary)')\n",
    "    else:\n",
    "        plt.pie(rainfall_counts.values, \n",
    "                labels=rainfall_counts.index, \n",
    "                autopct='%1.1f%%')\n",
    "        plt.title('Rainfall Distribution')\n",
    "else:\n",
    "    plt.text(0.5, 0.5, 'Rain column not found', ha='center', va='center')\n",
    "    plt.title('Rainfall Distribution - Data Not Available')\n",
    "\n",
    "# Rainfall vs temperature relationship\n",
    "plt.subplot(1, 3, 2)\n",
    "if rain_col in df.columns and temp_col in df.columns:\n",
    "    # Create binary rain for scatter plot\n",
    "    df_eda = df.copy()\n",
    "    df_eda['rain_binary'] = (df_eda[rain_col] > 0).astype(int)\n",
    "    sns.scatterplot(data=df_eda, x=temp_col, y=rain_col, hue='rain_binary', alpha=0.6)\n",
    "    plt.title('Temperature vs Rainfall')\n",
    "else:\n",
    "    plt.text(0.5, 0.5, 'Required columns not found', ha='center', va='center')\n",
    "    plt.title('Temperature vs Rainfall')\n",
    "\n",
    "# Time series of rainfall\n",
    "plt.subplot(1, 3, 3)\n",
    "if rain_col in df.columns and date_col in df.columns:\n",
    "    plt.plot(df[date_col], df[rain_col], alpha=0.7)\n",
    "    plt.title('Rainfall Over Time')\n",
    "    plt.xticks(rotation=45)\n",
    "else:\n",
    "    plt.text(0.5, 0.5, 'Required columns not found', ha='center', va='center')\n",
    "    plt.title('Rainfall Over Time')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6df2266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Grouped analysis by rainfall\n",
    "print(\"Grouped Analysis by Rainfall (Binary):\")\n",
    "\n",
    "# Create binary rainfall column for analysis\n",
    "df_eda = df.copy()\n",
    "if rain_col in df.columns:\n",
    "    df_eda['rain_binary'] = (df_eda[rain_col] > 0).astype(int)\n",
    "    \n",
    "    # Display grouped statistics\n",
    "    numeric_cols = df_eda.select_dtypes(include=[np.number]).columns\n",
    "    numeric_cols = [col for col in numeric_cols if col != 'rain_binary']\n",
    "    \n",
    "    if len(numeric_cols) > 0:\n",
    "        grouped_stats = df_eda.groupby('rain_binary')[numeric_cols].mean()\n",
    "        print(\"\\nMean values by rainfall status:\")\n",
    "        display(grouped_stats)\n",
    "        \n",
    "        # Key observations\n",
    "        print(\"\\nKey Observations:\")\n",
    "        if temp_col in numeric_cols:\n",
    "            temp_diff = grouped_stats[temp_col].diff().iloc[-1]\n",
    "            print(f\"- Temperature difference (Rain vs No Rain): {temp_diff:.2f}\")\n",
    "            \n",
    "        # Check for humidity column\n",
    "        humidity_cols = [col for col in df.columns if 'humid' in col.lower()]\n",
    "        if humidity_cols and humidity_cols[0] in numeric_cols:\n",
    "            humid_col = humidity_cols[0]\n",
    "            humid_diff = grouped_stats[humid_col].diff().iloc[-1]\n",
    "            print(f\"- Humidity difference (Rain vs No Rain): {humid_diff:.2f}\")\n",
    "            \n",
    "        # Check for cloud column\n",
    "        cloud_cols = [col for col in df.columns if 'cloud' in col.lower()]\n",
    "        if cloud_cols and cloud_cols[0] in numeric_cols:\n",
    "            cloud_col = cloud_cols[0]\n",
    "            cloud_diff = grouped_stats[cloud_col].diff().iloc[-1]\n",
    "            print(f\"- Cloud cover difference (Rain vs No Rain): {cloud_diff:.2f}\")\n",
    "            \n",
    "        # Check for wind speed\n",
    "        wind_cols = [col for col in df.columns if 'wind' in col.lower() and 'speed' in col.lower()]\n",
    "        if wind_cols and wind_cols[0] in numeric_cols:\n",
    "            wind_col = wind_cols[0]\n",
    "            wind_diff = grouped_stats[wind_col].diff().iloc[-1]\n",
    "            print(f\"- Wind speed difference (Rain vs No Rain): {wind_diff:.2f}\")\n",
    "else:\n",
    "    print(\"Rain column not available for grouped analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f3284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Distribution plots for all numeric features\n",
    "print(\"Distribution of Numeric Features:\")\n",
    "\n",
    "# Get numeric columns (excluding date and target columns)\n",
    "numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "# Remove date column if it was converted to numeric\n",
    "if date_col in numeric_features:\n",
    "    numeric_features.remove(date_col)\n",
    "# Remove target columns from features list\n",
    "if temp_col in numeric_features:\n",
    "    numeric_features.remove(temp_col)\n",
    "if rain_col in numeric_features:\n",
    "    numeric_features.remove(rain_col)\n",
    "\n",
    "print(f\"Numeric features to analyze: {numeric_features}\")\n",
    "\n",
    "if numeric_features:\n",
    "    # Calculate grid dimensions\n",
    "    n_features = len(numeric_features)\n",
    "    n_cols = 4\n",
    "    n_rows = (n_features + n_cols - 1) // n_cols\n",
    "    \n",
    "    plt.figure(figsize=(15, 4*n_rows))\n",
    "    \n",
    "    for i, feature in enumerate(numeric_features, 1):\n",
    "        plt.subplot(n_rows, n_cols, i)\n",
    "        sns.histplot(df[feature], kde=True, bins=30)\n",
    "        plt.title(f'Distribution of {feature}')\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No numeric features found for distribution analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcfbc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Box plots for outlier detection\n",
    "print(\"Box Plots for Outlier Detection:\")\n",
    "\n",
    "if numeric_features:\n",
    "    plt.figure(figsize=(15, 4*n_rows))\n",
    "    \n",
    "    for i, feature in enumerate(numeric_features, 1):\n",
    "        plt.subplot(n_rows, n_cols, i)\n",
    "        sns.boxplot(y=df[feature])\n",
    "        plt.title(f'Box Plot of {feature}')\n",
    "        plt.ylabel(feature)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Outlier analysis\n",
    "    print(\"\\nOutlier Analysis (using IQR method):\")\n",
    "    for feature in numeric_features:\n",
    "        Q1 = df[feature].quantile(0.25)\n",
    "        Q3 = df[feature].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        outliers = df[(df[feature] < lower_bound) | (df[feature] > upper_bound)]\n",
    "        print(f\"{feature}: {len(outliers)} outliers ({len(outliers)/len(df)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"No numeric features found for box plot analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638ddb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Correlation analysis\n",
    "print(\"Correlation Analysis:\")\n",
    "\n",
    "# Prepare data for correlation (include all numeric columns)\n",
    "corr_columns = [temp_col, rain_col] + numeric_features\n",
    "corr_columns = [col for col in corr_columns if col in df.columns]\n",
    "\n",
    "if len(corr_columns) > 1:\n",
    "    # Calculate correlation matrix\n",
    "    correlation_matrix = df[corr_columns].corr()\n",
    "    \n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))  # Mask upper triangle\n",
    "    sns.heatmap(correlation_matrix, \n",
    "                mask=mask,\n",
    "                annot=True, \n",
    "                cmap='coolwarm', \n",
    "                center=0,\n",
    "                square=True,\n",
    "                fmt='.2f',\n",
    "                cbar_kws={'shrink': 0.8})\n",
    "    plt.title('Feature Correlation Heatmap')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Identify highly correlated features\n",
    "    print(\"\\nHighly Correlated Features (|r| > 0.8):\")\n",
    "    high_corr_pairs = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            if abs(correlation_matrix.iloc[i, j]) > 0.8:\n",
    "                high_corr_pairs.append((\n",
    "                    correlation_matrix.columns[i],\n",
    "                    correlation_matrix.columns[j],\n",
    "                    correlation_matrix.iloc[i, j]\n",
    "                ))\n",
    "    \n",
    "    if high_corr_pairs:\n",
    "        for feature1, feature2, corr_value in high_corr_pairs:\n",
    "            print(f\"- {feature1} vs {feature2}: {corr_value:.3f}\")\n",
    "    else:\n",
    "        print(\"No highly correlated feature pairs found (|r| > 0.8)\")\n",
    "else:\n",
    "    print(\"Not enough numeric columns for correlation analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc0378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Time series analysis\n",
    "print(\"Time Series Analysis:\")\n",
    "\n",
    "if date_col in df.columns:\n",
    "    # Set date as index for time series plotting\n",
    "    df_time = df.set_index(date_col)\n",
    "    \n",
    "    # Plot temperature and rainfall over time\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 8))\n",
    "    \n",
    "    if temp_col in df.columns:\n",
    "        ax1.plot(df_time.index, df_time[temp_col], color='red', alpha=0.7)\n",
    "        ax1.set_ylabel('Temperature')\n",
    "        ax1.set_title('Temperature Over Time')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    if rain_col in df.columns:\n",
    "        ax2.plot(df_time.index, df_time[rain_col], color='blue', alpha=0.7)\n",
    "        ax2.set_ylabel('Rainfall')\n",
    "        ax2.set_title('Rainfall Over Time')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.set_xlabel('Date')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Seasonal patterns (if data spans multiple years)\n",
    "    if hasattr(df_time.index, 'month'):\n",
    "        print(\"\\nMonthly Patterns:\")\n",
    "        monthly_analysis = df_time.groupby(df_time.index.month)[\n",
    "    df_time.select_dtypes(include='number').columns\n",
    "].mean()\n",
    "        monthly_analysis.index = monthly_analysis.index.map({\n",
    "    1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun',\n",
    "    7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'\n",
    "})\n",
    "\n",
    "        if temp_col in monthly_analysis.columns:\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(monthly_analysis.index, monthly_analysis[temp_col], marker='o')\n",
    "            plt.title('Average Temperature by Month')\n",
    "            plt.xlabel('Month')\n",
    "            plt.ylabel('Temperature')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        if rain_col in monthly_analysis.columns:\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(monthly_analysis.index, monthly_analysis[rain_col], marker='o', color='green')\n",
    "            plt.title('Average Rainfall by Month')\n",
    "            plt.xlabel('Month')\n",
    "            plt.ylabel('Rainfall')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Date column not available for time series analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc20b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Data quality assessment\n",
    "print(\"Data Quality Assessment:\")\n",
    "\n",
    "# Check for skewness\n",
    "print(\"\\nSkewness of Numeric Features:\")\n",
    "for feature in numeric_features:\n",
    "    if feature in df.columns:\n",
    "        skewness = df[feature].skew()\n",
    "        print(f\"{feature}: {skewness:.3f} ({'Highly skewed' if abs(skewness) > 1 else 'Moderate' if abs(skewness) > 0.5 else 'Fairly symmetric'})\")\n",
    "\n",
    "# Check for constant columns\n",
    "constant_cols = []\n",
    "for col in df.columns:\n",
    "    if df[col].nunique() <= 1:\n",
    "        constant_cols.append(col)\n",
    "\n",
    "if constant_cols:\n",
    "    print(f\"\\nConstant columns (may consider removing): {constant_cols}\")\n",
    "else:\n",
    "    print(\"\\nNo constant columns found\")\n",
    "\n",
    "print(\"\\nEDA Complete! Proceeding to modeling...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a5f5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ddf73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1ff8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fa503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced model evaluation function\n",
    "def comprehensive_evaluate_models(X, y, target_name, n_splits=3):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation of models with detailed metrics and visualization\n",
    "    \"\"\"\n",
    "    tscv = TimeSeriesSplit(n_splits=max(1, min(n_splits, len(X)-1)))\n",
    "    models = {\n",
    "        'LinearRegression': Pipeline([('lr', LinearRegression())]),\n",
    "        'DecisionTree': Pipeline([('dt', DecisionTreeRegressor(random_state=42))]),\n",
    "        'SVR': Pipeline([('scaler', StandardScaler()), ('svr', SVR())])\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    all_predictions = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        maes, rmses, r2s, mapes = [], [], [], []\n",
    "        splits = list(tscv.split(X)) if len(X) > 1 else []\n",
    "        \n",
    "        if len(splits) == 0:\n",
    "            if len(X) < 2:\n",
    "                maes.append(np.nan); rmses.append(np.nan); r2s.append(np.nan); mapes.append(np.nan)\n",
    "            else:\n",
    "                train_idx = np.arange(max(1, len(X)-1)); test_idx = np.array([len(X)-1])\n",
    "                splits = [(train_idx, test_idx)]\n",
    "        \n",
    "        fold_predictions = []\n",
    "        \n",
    "        for fold, (train_idx, test_idx) in enumerate(splits):\n",
    "            Xtr, Xte = X[train_idx], X[test_idx]\n",
    "            ytr, yte = y[train_idx], y[test_idx]\n",
    "            \n",
    "            try:\n",
    "                model.fit(Xtr, ytr)\n",
    "                ypred = model.predict(Xte)\n",
    "                \n",
    "                # Calculate metrics\n",
    "                mae = mean_absolute_error(yte, ypred)\n",
    "                rmse = mean_squared_error(yte, ypred, squared=False)\n",
    "                r2 = r2_score(yte, ypred) if len(yte) > 1 else np.nan\n",
    "                mape = np.mean(np.abs((yte - ypred) / yte)) * 100 if np.all(yte != 0) else np.nan\n",
    "                \n",
    "                maes.append(mae)\n",
    "                rmses.append(rmse)\n",
    "                r2s.append(r2)\n",
    "                mapes.append(mape)\n",
    "                \n",
    "                # Store predictions for this fold\n",
    "                for true, pred in zip(yte, ypred):\n",
    "                    fold_predictions.append({\n",
    "                        'fold': fold,\n",
    "                        'actual': true,\n",
    "                        'predicted': pred,\n",
    "                        'error': true - pred\n",
    "                    })\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error in {name}, fold {fold}: {e}\")\n",
    "                maes.append(np.nan); rmses.append(np.nan); r2s.append(np.nan); mapes.append(np.nan)\n",
    "        \n",
    "        results[name] = {\n",
    "            'mae_mean': float(np.nanmean(maes)),\n",
    "            'mae_std': float(np.nanstd(maes)),\n",
    "            'rmse_mean': float(np.nanmean(rmses)),\n",
    "            'rmse_std': float(np.nanstd(rmses)),\n",
    "            'r2_mean': float(np.nanmean(r2s)),\n",
    "            'r2_std': float(np.nanstd(r2s)),\n",
    "            'mape_mean': float(np.nanmean(mapes)),\n",
    "            'model': model\n",
    "        }\n",
    "        all_predictions[name] = fold_predictions\n",
    "    \n",
    "    return results, all_predictions\n",
    "\n",
    "# FIRST: Run the comprehensive evaluation to get results AND predictions\n",
    "print(\"Comprehensive evaluation for Temperature...\")\n",
    "temp_results, temp_predictions = comprehensive_evaluate_models(X, y_temp, \"Temperature\")\n",
    "for name, res in temp_results.items():\n",
    "    print(f\" - {name}: MAE={res['mae_mean']:.4f}±{res['mae_std']:.4f}, \"\n",
    "          f\"RMSE={res['rmse_mean']:.4f}±{res['rmse_std']:.4f}, \"\n",
    "          f\"R²={res['r2_mean']:.4f}±{res['r2_std']:.4f}, \"\n",
    "          f\"MAPE={res['mape_mean']:.2f}%\")\n",
    "\n",
    "print(\"\\nComprehensive evaluation for Rainfall...\")\n",
    "rain_results, rain_predictions = comprehensive_evaluate_models(X, y_rain, \"Rainfall\")\n",
    "for name, res in rain_results.items():\n",
    "    print(f\" - {name}: MAE={res['mae_mean']:.4f}±{res['mae_std']:.4f}, \"\n",
    "          f\"RMSE={res['rmse_mean']:.4f}±{res['rmse_std']:.4f}, \"\n",
    "          f\"R²={res['r2_mean']:.4f}±{res['r2_std']:.4f}, \"\n",
    "          f\"MAPE={res['mape_mean']:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89969fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXED MODEL EVALUATION WITH PLOTS\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Set up matplotlib for Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"=== FIXED MODEL EVALUATION ===\")\n",
    "\n",
    "# 1. Basic Model Performance Table\n",
    "print(\"\\nMODEL PERFORMANCE SUMMARY:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Model':<15} {'Target':<12} {'MAE':<8} {'RMSE':<8} {'R²':<8}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Evaluate each model simply\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'DecisionTree': DecisionTreeRegressor(random_state=42),\n",
    "    'SVR': Pipeline([('scaler', StandardScaler()), ('svr', SVR())])\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Temperature\n",
    "    model.fit(X, y_temp)\n",
    "    temp_pred = model.predict(X)\n",
    "    temp_mae = mean_absolute_error(y_temp, temp_pred)\n",
    "    temp_rmse = np.sqrt(mean_squared_error(y_temp, temp_pred))  # FIXED: Manual RMSE calculation\n",
    "    temp_r2 = r2_score(y_temp, temp_pred)\n",
    "    \n",
    "    # Rainfall  \n",
    "    model.fit(X, y_rain)\n",
    "    rain_pred = model.predict(X)\n",
    "    rain_mae = mean_absolute_error(y_rain, rain_pred)\n",
    "    rain_rmse = np.sqrt(mean_squared_error(y_rain, rain_pred))  # FIXED: Manual RMSE calculation\n",
    "    rain_r2 = r2_score(y_rain, rain_pred)\n",
    "    \n",
    "    print(f\"{model_name:<15} {'Temperature':<12} {temp_mae:<8.3f} {temp_rmse:<8.3f} {temp_r2:<8.3f}\")\n",
    "    print(f\"{model_name:<15} {'Rainfall':<12} {rain_mae:<8.3f} {rain_rmse:<8.3f} {rain_r2:<8.3f}\")\n",
    "\n",
    "# 2. Simple Actual vs Predicted Plots\n",
    "print(\"\\nCREATING BASIC PLOTS...\")\n",
    "\n",
    "# Temperature predictions\n",
    "best_temp_model = LinearRegression()\n",
    "best_temp_model.fit(X, y_temp)\n",
    "temp_predictions = best_temp_model.predict(X)\n",
    "\n",
    "# Rainfall predictions\n",
    "best_rain_model = LinearRegression() \n",
    "best_rain_model.fit(X, y_rain)\n",
    "rain_predictions = best_rain_model.predict(X)\n",
    "\n",
    "# Create the plots\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Temperature - Actual vs Predicted\n",
    "ax1.scatter(y_temp, temp_predictions, alpha=0.7, color='red')\n",
    "ax1.plot([y_temp.min(), y_temp.max()], [y_temp.min(), y_temp.max()], 'k--', lw=2)\n",
    "ax1.set_xlabel('Actual Temperature (°C)')\n",
    "ax1.set_ylabel('Predicted Temperature (°C)')\n",
    "ax1.set_title('Temperature: Actual vs Predicted')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add metrics to plot\n",
    "temp_r2 = r2_score(y_temp, temp_predictions)\n",
    "temp_mae = mean_absolute_error(y_temp, temp_predictions)\n",
    "ax1.text(0.05, 0.95, f'R² = {temp_r2:.3f}\\nMAE = {temp_mae:.3f}', \n",
    "         transform=ax1.transAxes, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "# Temperature - Residuals\n",
    "temp_residuals = y_temp - temp_predictions\n",
    "ax2.scatter(temp_predictions, temp_residuals, alpha=0.7, color='red')\n",
    "ax2.axhline(y=0, color='k', linestyle='--')\n",
    "ax2.set_xlabel('Predicted Temperature (°C)')\n",
    "ax2.set_ylabel('Residuals')\n",
    "ax2.set_title('Temperature: Residual Plot')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add residual stats\n",
    "ax2.text(0.05, 0.95, f'Mean Residual: {np.mean(temp_residuals):.3f}', \n",
    "         transform=ax2.transAxes, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "# Rainfall - Actual vs Predicted\n",
    "ax3.scatter(y_rain, rain_predictions, alpha=0.7, color='blue')\n",
    "ax3.plot([y_rain.min(), y_rain.max()], [y_rain.min(), y_rain.max()], 'k--', lw=2)\n",
    "ax3.set_xlabel('Actual Rainfall (mm)')\n",
    "ax3.set_ylabel('Predicted Rainfall (mm)')\n",
    "ax3.set_title('Rainfall: Actual vs Predicted')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Add metrics to plot\n",
    "rain_r2 = r2_score(y_rain, rain_predictions)\n",
    "rain_mae = mean_absolute_error(y_rain, rain_predictions)\n",
    "ax3.text(0.05, 0.95, f'R² = {rain_r2:.3f}\\nMAE = {rain_mae:.3f}', \n",
    "         transform=ax3.transAxes, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "# Rainfall - Residuals\n",
    "rain_residuals = y_rain - rain_predictions\n",
    "ax4.scatter(rain_predictions, rain_residuals, alpha=0.7, color='blue')\n",
    "ax4.axhline(y=0, color='k', linestyle='--')\n",
    "ax4.set_xlabel('Predicted Rainfall (mm)')\n",
    "ax4.set_ylabel('Residuals')\n",
    "ax4.set_title('Rainfall: Residual Plot')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Add residual stats\n",
    "ax4.text(0.05, 0.95, f'Mean Residual: {np.mean(rain_residuals):.3f}', \n",
    "         transform=ax4.transAxes, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Basic plots created successfully!\")\n",
    "\n",
    "# 3. Model Comparison Bar Chart\n",
    "print(\"\\nCREATING MODEL COMPARISON CHART...\")\n",
    "\n",
    "models_mae_temp = []\n",
    "models_mae_rain = []\n",
    "models_rmse_temp = []\n",
    "models_rmse_rain = []\n",
    "model_names = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Temperature metrics\n",
    "    model.fit(X, y_temp)\n",
    "    temp_pred = model.predict(X)\n",
    "    temp_mae = mean_absolute_error(y_temp, temp_pred)\n",
    "    temp_rmse = np.sqrt(mean_squared_error(y_temp, temp_pred))\n",
    "    models_mae_temp.append(temp_mae)\n",
    "    models_rmse_temp.append(temp_rmse)\n",
    "    \n",
    "    # Rainfall metrics\n",
    "    model.fit(X, y_rain) \n",
    "    rain_pred = model.predict(X)\n",
    "    rain_mae = mean_absolute_error(y_rain, rain_pred)\n",
    "    rain_rmse = np.sqrt(mean_squared_error(y_rain, rain_pred))\n",
    "    models_mae_rain.append(rain_mae)\n",
    "    models_rmse_rain.append(rain_rmse)\n",
    "    \n",
    "    model_names.append(model_name)\n",
    "\n",
    "# Create comparison plot\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Temperature MAE comparison\n",
    "bars1 = ax1.bar(model_names, models_mae_temp, color=['red', 'orange', 'green'], alpha=0.7)\n",
    "ax1.set_ylabel('MAE (Temperature °C)')\n",
    "ax1.set_title('Model Comparison - Temperature MAE')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Temperature RMSE comparison  \n",
    "bars2 = ax2.bar(model_names, models_rmse_temp, color=['red', 'orange', 'green'], alpha=0.7)\n",
    "ax2.set_ylabel('RMSE (Temperature °C)')\n",
    "ax2.set_title('Model Comparison - Temperature RMSE')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Rainfall MAE comparison  \n",
    "bars3 = ax3.bar(model_names, models_mae_rain, color=['red', 'orange', 'green'], alpha=0.7)\n",
    "ax3.set_ylabel('MAE (Rainfall mm)')\n",
    "ax3.set_title('Model Comparison - Rainfall MAE')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars3:\n",
    "    height = bar.get_height()\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Rainfall RMSE comparison  \n",
    "bars4 = ax4.bar(model_names, models_rmse_rain, color=['red', 'orange', 'green'], alpha=0.7)\n",
    "ax4.set_ylabel('RMSE (Rainfall mm)')\n",
    "ax4.set_title('Model Comparison - Rainfall RMSE')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars4:\n",
    "    height = bar.get_height()\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Model comparison chart created successfully!\")\n",
    "\n",
    "# 4. Final Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RECOMMENDATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_temp_mae_idx = np.argmin(models_mae_temp)\n",
    "best_rain_mae_idx = np.argmin(models_mae_rain)\n",
    "best_temp_rmse_idx = np.argmin(models_rmse_temp)\n",
    "best_rain_rmse_idx = np.argmin(models_rmse_rain)\n",
    "\n",
    "print(f\"Best model for Temperature (MAE): {model_names[best_temp_mae_idx]} (MAE: {models_mae_temp[best_temp_mae_idx]:.3f}°C)\")\n",
    "print(f\"Best model for Rainfall (MAE): {model_names[best_rain_mae_idx]} (MAE: {models_mae_rain[best_rain_mae_idx]:.3f}mm)\")\n",
    "print(f\"Best model for Temperature (RMSE): {model_names[best_temp_rmse_idx]} (RMSE: {models_rmse_temp[best_temp_rmse_idx]:.3f}°C)\")\n",
    "print(f\"Best model for Rainfall (RMSE): {model_names[best_rain_rmse_idx]} (RMSE: {models_rmse_rain[best_rain_rmse_idx]:.3f}mm)\")\n",
    "\n",
    "print(\"\\nPERFORMANCE ASSESSMENT:\")\n",
    "if models_mae_temp[best_temp_mae_idx] < 1.0:\n",
    "    print(\"Temperature prediction: EXCELLENT\")\n",
    "elif models_mae_temp[best_temp_mae_idx] < 2.0:\n",
    "    print(\"Temperature prediction: GOOD\") \n",
    "else:\n",
    "    print(\"Temperature prediction: NEEDS IMPROVEMENT\")\n",
    "\n",
    "if models_mae_rain[best_rain_mae_idx] < 5.0:\n",
    "    print(\"Rainfall prediction: EXCELLENT\")\n",
    "elif models_mae_rain[best_rain_mae_idx] < 10.0:\n",
    "    print(\"Rainfall prediction: GOOD\")\n",
    "else:\n",
    "    print(\"Rainfall prediction: NEEDS IMPROVEMENT\")\n",
    "\n",
    "# 5. Show sample predictions vs actual\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAMPLE PREDICTIONS vs ACTUAL VALUES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"{'Date':<12} {'Actual Temp':<12} {'Pred Temp':<12} {'Error':<10} {'Actual Rain':<12} {'Pred Rain':<12} {'Error':<10}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "# Get dates from the cleaned dataframe\n",
    "dates = df_clean.index[-len(y_temp):] if hasattr(df_clean, 'index') else range(len(y_temp))\n",
    "\n",
    "for i in range(min(5, len(y_temp))):\n",
    "    date_str = str(dates[i]) if i < len(dates) else f\"Day_{i+1}\"\n",
    "    temp_error = y_temp[i] - temp_predictions[i]\n",
    "    rain_error = y_rain[i] - rain_predictions[i]\n",
    "    \n",
    "    print(f\"{date_str:<12} {y_temp[i]:<12.2f} {temp_predictions[i]:<12.2f} {temp_error:<10.2f} \"\n",
    "          f\"{y_rain[i]:<12.2f} {rain_predictions[i]:<12.2f} {rain_error:<10.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b614d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal features\n",
    "df_feat['day_of_year'] = df_feat.index.dayofyear\n",
    "df_feat['month'] = df_feat.index.month\n",
    "df_feat['season'] = (df_feat.index.month % 12 + 3) // 3\n",
    "\n",
    "# Weather-specific features\n",
    "df_feat['temp_change'] = df_feat[temp_col] - df_feat[f'temp_lag_1']\n",
    "df_feat['rain_change'] = df_feat[rain_col] - df_feat[f'rain_lag_1']"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
