{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85085170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and configuration\n",
    "import os, sqlite3, warnings\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Paths (change if needed)\n",
    "CSV_PATH = r\"C:\\Users\\hp\\OneDrive\\Desktop\\Weather Prediction Model\\weather_data.csv\"   # <- change this if your CSV is elsewhere\n",
    "OUTDIR = \"/mnt/data\"\n",
    "DB_PATH = os.path.join(OUTDIR, \"weather_weather.db\")\n",
    "PRED_CSV_PATH = os.path.join(OUTDIR, \"weather_predictions.csv\")\n",
    "\n",
    "print('CSV_PATH =', CSV_PATH)\n",
    "print('Outputs will be saved to:', OUTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2b46e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV and basic checks\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    raise FileNotFoundError(f'CSV not found at {CSV_PATH}. Upload your CSV or change CSV_PATH.')\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print('Loaded CSV with shape:', df.shape)\n",
    "display(df.head())\n",
    "\n",
    "# helper to detect columns\n",
    "def find_date_column(df):\n",
    "    for col in df.columns:\n",
    "        if col.lower() in ('date','datetime','day','timestamp'):\n",
    "            return col\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            pd.to_datetime(df[col])\n",
    "            return col\n",
    "        except Exception:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "def find_temp_and_rain_columns(df):\n",
    "    temp_col = None; rain_col = None\n",
    "    for col in df.columns:\n",
    "        lname = col.lower()\n",
    "        if temp_col is None and ('temp' in lname or 'temperature' in lname):\n",
    "            temp_col = col\n",
    "        if rain_col is None and ('rain' in lname or 'precip' in lname):\n",
    "            rain_col = col\n",
    "    return temp_col, rain_col\n",
    "\n",
    "date_col = find_date_column(df)\n",
    "if date_col is not None:\n",
    "    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "    df = df.sort_values(by=date_col).reset_index(drop=True)\n",
    "else:\n",
    "    df = df.reset_index().rename(columns={'index':'synthetic_index'})\n",
    "    date_col = 'synthetic_index'\n",
    "    df[date_col] = pd.to_datetime(df[date_col], unit='D', origin='1970-01-01')\n",
    "\n",
    "temp_col, rain_col = find_temp_and_rain_columns(df)\n",
    "if temp_col is None or rain_col is None:\n",
    "    raise ValueError('Could not detect temp or rain columns. Ensure names include \"temp\" and \"rain\"/\"precip\".\\nFound columns: ' + ', '.join(df.columns))\n",
    "\n",
    "df[temp_col] = pd.to_numeric(df[temp_col], errors='coerce')\n",
    "df[rain_col] = pd.to_numeric(df[rain_col], errors='coerce')\n",
    "df = df.dropna(subset=[temp_col, rain_col], how='all').reset_index(drop=True)\n",
    "\n",
    "print('Using date_col =', date_col, ', temp_col =', temp_col, ', rain_col =', rain_col)\n",
    "print('\\nLast 5 rows:')\n",
    "display(df.tail())\n",
    "\n",
    "# Save raw table to SQLite DB (replace)\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "df_for_db = df.copy()\n",
    "if 'predicted' not in df_for_db.columns:\n",
    "    df_for_db['predicted'] = 0\n",
    "df_for_db.to_sql('weather', conn, if_exists='replace', index=False)\n",
    "conn.commit(); conn.close()\n",
    "print('Saved raw data to DB at', DB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3459a82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern analysis (last 7 days) and feature engineering\n",
    "last7 = df.tail(7).copy()\n",
    "print('Pattern analysis (last 7 days):')\n",
    "temps = last7[temp_col].values\n",
    "rains = last7[rain_col].values\n",
    "print(' - temp_mean:', float(np.nanmean(temps)))\n",
    "print(' - temp_median:', float(np.nanmedian(temps)))\n",
    "print(' - temp_std:', float(np.nanstd(temps)))\n",
    "print(' - temp_trend:', 'increasing' if temps[-1] > temps[0] else ('decreasing' if temps[-1] < temps[0] else 'flat'))\n",
    "print(' - rain_total:', float(np.nansum(rains)))\n",
    "print(' - rain_days:', int(np.sum(~np.isnan(rains) & (rains>0))))\n",
    "\n",
    "# plots for last 7 days\n",
    "plt.figure(figsize=(8,3)); plt.plot(last7[date_col], last7[temp_col], marker='o'); plt.title('Temperature - last 7 days'); plt.xlabel('Date'); plt.ylabel('Temperature'); plt.tight_layout(); plt.show()\n",
    "plt.figure(figsize=(8,3)); plt.plot(last7[date_col], last7[rain_col], marker='o'); plt.title('Rainfall - last 7 days'); plt.xlabel('Date'); plt.ylabel('Rainfall'); plt.tight_layout(); plt.show()\n",
    "\n",
    "# Feature engineering: lags and rolling features\n",
    "nlags = 3\n",
    "df_feat = df[[date_col, temp_col, rain_col]].copy().set_index(date_col)\n",
    "for lag in range(1, nlags+1):\n",
    "    df_feat[f'temp_lag_{lag}'] = df_feat[temp_col].shift(lag)\n",
    "    df_feat[f'rain_lag_{lag}'] = df_feat[rain_col].shift(lag)\n",
    "df_feat['temp_roll_3'] = df_feat[temp_col].rolling(window=3, min_periods=1).mean().shift(1)\n",
    "df_feat['rain_roll_3'] = df_feat[rain_col].rolling(window=3, min_periods=1).mean().shift(1)\n",
    "\n",
    "df_clean = df_feat.dropna().copy()\n",
    "print('\\nAfter feature creation, rows available for modelling:', len(df_clean))\n",
    "display(df_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc6c14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling and evaluation (Temperature and Rainfall separately)\n",
    "feature_cols = [c for c in df_clean.columns if c not in (temp_col, rain_col)]\n",
    "X = df_clean[feature_cols].values\n",
    "y_temp = df_clean[temp_col].values\n",
    "y_rain = df_clean[rain_col].values\n",
    "\n",
    "def evaluate_models(X, y, n_splits=3):\n",
    "    tscv = TimeSeriesSplit(n_splits=max(1, min(n_splits, len(X)-1)))\n",
    "    models = {\n",
    "        'LinearRegression': Pipeline([('lr', LinearRegression())]),\n",
    "        'DecisionTree': Pipeline([('dt', DecisionTreeRegressor(random_state=42))]),\n",
    "        'SVR': Pipeline([('scaler', StandardScaler()), ('svr', SVR())])\n",
    "    }\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        maes, rmses, r2s = [], [], []\n",
    "        splits = list(tscv.split(X)) if len(X) > 1 else []\n",
    "        if len(splits) == 0:\n",
    "            if len(X) < 2:\n",
    "                maes.append(np.nan); rmses.append(np.nan); r2s.append(np.nan)\n",
    "            else:\n",
    "                train_idx = np.arange(max(1, len(X)-1)); test_idx = np.array([len(X)-1]); splits = [(train_idx, test_idx)]\n",
    "        for train_idx, test_idx in splits:\n",
    "            Xtr, Xte = X[train_idx], X[test_idx]\n",
    "            ytr, yte = y[train_idx], y[test_idx]\n",
    "            try:\n",
    "                model.fit(Xtr, ytr)\n",
    "                ypred = model.predict(Xte)\n",
    "                maes.append(mean_absolute_error(yte, ypred))\n",
    "                rmses.append(mean_squared_error(yte, ypred, squared=False))\n",
    "                r2s.append(r2_score(yte, ypred) if len(yte)>1 else np.nan)\n",
    "            except Exception as e:\n",
    "                maes.append(np.nan); rmses.append(np.nan); r2s.append(np.nan)\n",
    "        results[name] = {'mae_mean': float(np.nanmean(maes)), 'rmse_mean': float(np.nanmean(rmses)), 'r2_mean': float(np.nanmean(r2s)), 'model': model}\n",
    "    return results\n",
    "\n",
    "print('Training & evaluating models for Temperature...')\n",
    "temp_results = evaluate_models(X, y_temp, n_splits=3)\n",
    "for name, res in temp_results.items():\n",
    "    print(f\" - {name}: MAE={res['mae_mean']:.4f}, RMSE={res['rmse_mean']:.4f}, R2={res['r2_mean']:.4f}\")\n",
    "\n",
    "print('\\nTraining & evaluating models for Rainfall...')\n",
    "rain_results = evaluate_models(X, y_rain, n_splits=3)\n",
    "for name, res in rain_results.items():\n",
    "    print(f\" - {name}: MAE={res['mae_mean']:.4f}, RMSE={res['rmse_mean']:.4f}, R2={res['r2_mean']:.4f}\")\n",
    "\n",
    "# Choose best by RMSE\n",
    "best_temp_name = min(temp_results.keys(), key=lambda k: temp_results[k]['rmse_mean'] if not np.isnan(temp_results[k]['rmse_mean']) else 1e9)\n",
    "best_rain_name = min(rain_results.keys(), key=lambda k: rain_results[k]['rmse_mean'] if not np.isnan(rain_results[k]['rmse_mean']) else 1e9)\n",
    "best_temp_model = temp_results[best_temp_name]['model']\n",
    "best_rain_model = rain_results[best_rain_name]['model']\n",
    "\n",
    "# Fit on entire cleaned data\n",
    "best_temp_model.fit(X, y_temp)\n",
    "best_rain_model.fit(X, y_rain)\n",
    "print('\\nSelected models -> Temperature:', best_temp_name, ', Rainfall:', best_rain_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e733a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next-day (8th day) prediction and save outputs\n",
    "# Prepare next-day features from most recent values\n",
    "last_index = df_feat.index.max()\n",
    "next_features = {}\n",
    "for lag in range(1, nlags+1):\n",
    "    next_features[f'temp_lag_{lag}'] = df_feat[temp_col].iloc[-lag] if len(df_feat) >= lag else np.nan\n",
    "    next_features[f'rain_lag_{lag}'] = df_feat[rain_col].iloc[-lag] if len(df_feat) >= lag else np.nan\n",
    "next_features['temp_roll_3'] = df_feat[temp_col].tail(3).mean() if len(df_feat) >= 1 else np.nan\n",
    "next_features['rain_roll_3'] = df_feat[rain_col].tail(3).mean() if len(df_feat) >= 1 else np.nan\n",
    "\n",
    "X_next = np.array([next_features[c] for c in feature_cols]).reshape(1, -1)\n",
    "temp_pred = best_temp_model.predict(X_next)[0]\n",
    "rain_pred = best_rain_model.predict(X_next)[0]\n",
    "\n",
    "# compute predicted date (assume daily)\n",
    "try:\n",
    "    if isinstance(last_index, pd.Timestamp):\n",
    "        if len(df_feat.index) >= 2:\n",
    "            delta = df_feat.index[-1] - df_feat.index[-2]\n",
    "            next_date = df_feat.index[-1] + delta\n",
    "        else:\n",
    "            next_date = df_feat.index[-1] + timedelta(days=1)\n",
    "    else:\n",
    "        next_date = pd.to_datetime(df_feat.index.max()) + timedelta(days=1)\n",
    "except Exception:\n",
    "    next_date = pd.to_datetime(df_feat.index.max()) + timedelta(days=1)\n",
    "\n",
    "pred_row = {date_col: next_date, temp_col: float(temp_pred), rain_col: float(rain_pred)}\n",
    "pred_row['predicted'] = 1\n",
    "pred_row['model_temp'] = best_temp_name\n",
    "pred_row['model_rain'] = best_rain_name\n",
    "pred_row.update(next_features)\n",
    "\n",
    "pred_df = pd.DataFrame([pred_row])\n",
    "print('\\nNext-day prediction (8th day):')\n",
    "display(pred_df.rename(columns={date_col: 'date', temp_col: 'temperature', rain_col: 'rainfall'}))\n",
    "\n",
    "# Append prediction to DB\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "df_for_db = pd.read_sql_query('SELECT * FROM weather LIMIT 1;', conn)  # just to get schema\n",
    "pred_to_write = pred_df.copy()\n",
    "# ensure all columns exist\n",
    "for col in df_for_db.columns:\n",
    "    if col not in pred_to_write.columns:\n",
    "        pred_to_write[col] = np.nan\n",
    "pred_to_write = pred_to_write[df_for_db.columns]\n",
    "pred_to_write.to_sql('weather', conn, if_exists='append', index=False)\n",
    "conn.commit(); conn.close()\n",
    "print('Appended prediction to DB at', DB_PATH)\n",
    "\n",
    "# Save prediction CSV\n",
    "out_pred = pred_df.rename(columns={date_col: 'date', temp_col: 'temperature', rain_col: 'rainfall'})\n",
    "out_pred.to_csv(PRED_CSV_PATH, index=False)\n",
    "print('Saved prediction CSV to', PRED_CSV_PATH)\n",
    "\n",
    "# Plots: actual vs predicted for last part\n",
    "try:\n",
    "    y_temp_all = best_temp_model.predict(X)\n",
    "    y_rain_all = best_rain_model.predict(X)\n",
    "    nplot = min(30, len(df_clean))\n",
    "    idx = df_clean.index[-nplot:]\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.plot(idx, df_clean[temp_col].iloc[-nplot:], label='actual')\n",
    "    plt.plot(idx, y_temp_all[-nplot:], linestyle='--', label='predicted')\n",
    "    plt.title('Temperature: Actual vs Predicted (last points)'); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.plot(idx, df_clean[rain_col].iloc[-nplot:], label='actual')\n",
    "    plt.plot(idx, y_rain_all[-nplot:], linestyle='--', label='predicted')\n",
    "    plt.title('Rainfall: Actual vs Predicted (last points)'); plt.legend(); plt.tight_layout(); plt.show()\n",
    "except Exception as e:\n",
    "    print('Plotting failed:', e)\n",
    "\n",
    "print('\\nNotebook run complete. Outputs:') \n",
    "print(' - Prediction CSV:', PRED_CSV_PATH)\n",
    "print(' - SQLite DB:', DB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3261f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import additional libraries for EDA\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"=== EXPLORATORY DATA ANALYSIS ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96105f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Basic data overview and statistics\n",
    "print(\"Dataset Overview:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(\"\\nBasic Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "display(df.describe())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab1c673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Rainfall distribution analysis\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Pie chart for rainfall distribution\n",
    "plt.subplot(1, 3, 1)\n",
    "if rain_col in df.columns:\n",
    "    rainfall_counts = df[rain_col].value_counts()\n",
    "    # Convert to binary (rain/no rain) if continuous\n",
    "    if rainfall_counts.shape[0] > 10:  # If continuous, create binary\n",
    "        df_rain_binary = (df[rain_col] > 0).astype(int)\n",
    "        rainfall_binary_counts = df_rain_binary.value_counts()\n",
    "        plt.pie(rainfall_binary_counts.values, \n",
    "                labels=['No Rain', 'Rain'], \n",
    "                autopct='%1.1f%%', \n",
    "                colors=['skyblue', 'lightcoral'])\n",
    "        plt.title('Rainfall Distribution (Binary)')\n",
    "    else:\n",
    "        plt.pie(rainfall_counts.values, \n",
    "                labels=rainfall_counts.index, \n",
    "                autopct='%1.1f%%')\n",
    "        plt.title('Rainfall Distribution')\n",
    "else:\n",
    "    plt.text(0.5, 0.5, 'Rain column not found', ha='center', va='center')\n",
    "    plt.title('Rainfall Distribution - Data Not Available')\n",
    "\n",
    "# Rainfall vs temperature relationship\n",
    "plt.subplot(1, 3, 2)\n",
    "if rain_col in df.columns and temp_col in df.columns:\n",
    "    # Create binary rain for scatter plot\n",
    "    df_eda = df.copy()\n",
    "    df_eda['rain_binary'] = (df_eda[rain_col] > 0).astype(int)\n",
    "    sns.scatterplot(data=df_eda, x=temp_col, y=rain_col, hue='rain_binary', alpha=0.6)\n",
    "    plt.title('Temperature vs Rainfall')\n",
    "else:\n",
    "    plt.text(0.5, 0.5, 'Required columns not found', ha='center', va='center')\n",
    "    plt.title('Temperature vs Rainfall')\n",
    "\n",
    "# Time series of rainfall\n",
    "plt.subplot(1, 3, 3)\n",
    "if rain_col in df.columns and date_col in df.columns:\n",
    "    plt.plot(df[date_col], df[rain_col], alpha=0.7)\n",
    "    plt.title('Rainfall Over Time')\n",
    "    plt.xticks(rotation=45)\n",
    "else:\n",
    "    plt.text(0.5, 0.5, 'Required columns not found', ha='center', va='center')\n",
    "    plt.title('Rainfall Over Time')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6df2266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Grouped analysis by rainfall\n",
    "print(\"Grouped Analysis by Rainfall (Binary):\")\n",
    "\n",
    "# Create binary rainfall column for analysis\n",
    "df_eda = df.copy()\n",
    "if rain_col in df.columns:\n",
    "    df_eda['rain_binary'] = (df_eda[rain_col] > 0).astype(int)\n",
    "    \n",
    "    # Display grouped statistics\n",
    "    numeric_cols = df_eda.select_dtypes(include=[np.number]).columns\n",
    "    numeric_cols = [col for col in numeric_cols if col != 'rain_binary']\n",
    "    \n",
    "    if len(numeric_cols) > 0:\n",
    "        grouped_stats = df_eda.groupby('rain_binary')[numeric_cols].mean()\n",
    "        print(\"\\nMean values by rainfall status:\")\n",
    "        display(grouped_stats)\n",
    "        \n",
    "        # Key observations\n",
    "        print(\"\\nKey Observations:\")\n",
    "        if temp_col in numeric_cols:\n",
    "            temp_diff = grouped_stats[temp_col].diff().iloc[-1]\n",
    "            print(f\"- Temperature difference (Rain vs No Rain): {temp_diff:.2f}\")\n",
    "            \n",
    "        # Check for humidity column\n",
    "        humidity_cols = [col for col in df.columns if 'humid' in col.lower()]\n",
    "        if humidity_cols and humidity_cols[0] in numeric_cols:\n",
    "            humid_col = humidity_cols[0]\n",
    "            humid_diff = grouped_stats[humid_col].diff().iloc[-1]\n",
    "            print(f\"- Humidity difference (Rain vs No Rain): {humid_diff:.2f}\")\n",
    "            \n",
    "        # Check for cloud column\n",
    "        cloud_cols = [col for col in df.columns if 'cloud' in col.lower()]\n",
    "        if cloud_cols and cloud_cols[0] in numeric_cols:\n",
    "            cloud_col = cloud_cols[0]\n",
    "            cloud_diff = grouped_stats[cloud_col].diff().iloc[-1]\n",
    "            print(f\"- Cloud cover difference (Rain vs No Rain): {cloud_diff:.2f}\")\n",
    "            \n",
    "        # Check for wind speed\n",
    "        wind_cols = [col for col in df.columns if 'wind' in col.lower() and 'speed' in col.lower()]\n",
    "        if wind_cols and wind_cols[0] in numeric_cols:\n",
    "            wind_col = wind_cols[0]\n",
    "            wind_diff = grouped_stats[wind_col].diff().iloc[-1]\n",
    "            print(f\"- Wind speed difference (Rain vs No Rain): {wind_diff:.2f}\")\n",
    "else:\n",
    "    print(\"Rain column not available for grouped analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f3284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Distribution plots for all numeric features\n",
    "print(\"Distribution of Numeric Features:\")\n",
    "\n",
    "# Get numeric columns (excluding date and target columns)\n",
    "numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "# Remove date column if it was converted to numeric\n",
    "if date_col in numeric_features:\n",
    "    numeric_features.remove(date_col)\n",
    "# Remove target columns from features list\n",
    "if temp_col in numeric_features:\n",
    "    numeric_features.remove(temp_col)\n",
    "if rain_col in numeric_features:\n",
    "    numeric_features.remove(rain_col)\n",
    "\n",
    "print(f\"Numeric features to analyze: {numeric_features}\")\n",
    "\n",
    "if numeric_features:\n",
    "    # Calculate grid dimensions\n",
    "    n_features = len(numeric_features)\n",
    "    n_cols = 4\n",
    "    n_rows = (n_features + n_cols - 1) // n_cols\n",
    "    \n",
    "    plt.figure(figsize=(15, 4*n_rows))\n",
    "    \n",
    "    for i, feature in enumerate(numeric_features, 1):\n",
    "        plt.subplot(n_rows, n_cols, i)\n",
    "        sns.histplot(df[feature], kde=True, bins=30)\n",
    "        plt.title(f'Distribution of {feature}')\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No numeric features found for distribution analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcfbc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Box plots for outlier detection\n",
    "print(\"Box Plots for Outlier Detection:\")\n",
    "\n",
    "if numeric_features:\n",
    "    plt.figure(figsize=(15, 4*n_rows))\n",
    "    \n",
    "    for i, feature in enumerate(numeric_features, 1):\n",
    "        plt.subplot(n_rows, n_cols, i)\n",
    "        sns.boxplot(y=df[feature])\n",
    "        plt.title(f'Box Plot of {feature}')\n",
    "        plt.ylabel(feature)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Outlier analysis\n",
    "    print(\"\\nOutlier Analysis (using IQR method):\")\n",
    "    for feature in numeric_features:\n",
    "        Q1 = df[feature].quantile(0.25)\n",
    "        Q3 = df[feature].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        outliers = df[(df[feature] < lower_bound) | (df[feature] > upper_bound)]\n",
    "        print(f\"{feature}: {len(outliers)} outliers ({len(outliers)/len(df)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"No numeric features found for box plot analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638ddb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Correlation analysis\n",
    "print(\"Correlation Analysis:\")\n",
    "\n",
    "# Prepare data for correlation (include all numeric columns)\n",
    "corr_columns = [temp_col, rain_col] + numeric_features\n",
    "corr_columns = [col for col in corr_columns if col in df.columns]\n",
    "\n",
    "if len(corr_columns) > 1:\n",
    "    # Calculate correlation matrix\n",
    "    correlation_matrix = df[corr_columns].corr()\n",
    "    \n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))  # Mask upper triangle\n",
    "    sns.heatmap(correlation_matrix, \n",
    "                mask=mask,\n",
    "                annot=True, \n",
    "                cmap='coolwarm', \n",
    "                center=0,\n",
    "                square=True,\n",
    "                fmt='.2f',\n",
    "                cbar_kws={'shrink': 0.8})\n",
    "    plt.title('Feature Correlation Heatmap')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Identify highly correlated features\n",
    "    print(\"\\nHighly Correlated Features (|r| > 0.8):\")\n",
    "    high_corr_pairs = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            if abs(correlation_matrix.iloc[i, j]) > 0.8:\n",
    "                high_corr_pairs.append((\n",
    "                    correlation_matrix.columns[i],\n",
    "                    correlation_matrix.columns[j],\n",
    "                    correlation_matrix.iloc[i, j]\n",
    "                ))\n",
    "    \n",
    "    if high_corr_pairs:\n",
    "        for feature1, feature2, corr_value in high_corr_pairs:\n",
    "            print(f\"- {feature1} vs {feature2}: {corr_value:.3f}\")\n",
    "    else:\n",
    "        print(\"No highly correlated feature pairs found (|r| > 0.8)\")\n",
    "else:\n",
    "    print(\"Not enough numeric columns for correlation analysis\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
